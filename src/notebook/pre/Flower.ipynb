{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iamsdt/UdacityPyTorch/blob/master/src/notebook/pre/Flower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GhicfaLjUxFV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pzXqpSuHU1X3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55bxR_GDU4A6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-h2cC9VU7Kj",
        "colab_type": "code",
        "outputId": "c236d300-bf5b-4e26-88bc-b1bd15c38527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "# create train and test loader\n",
        "data_dir = 'flower_data'\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transform_valid = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "#data set\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=transform_train)\n",
        "\n",
        "valid_data = datasets.ImageFolder(data_dir + '/train', transform=transform_valid)\n",
        "\n",
        "test_data = datasets.ImageFolder(data_dir + '/valid', transform=test_transforms)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "print(num_train)\n",
        " \n",
        "print(len(valid_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6552\n",
            "6552\n",
            "818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ai0NHAEQU_kM",
        "colab_type": "code",
        "outputId": "af48348c-fa53-4532-ade0-44b180bef807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# index of num of train\n",
        "indices = list(range(num_train))\n",
        "#random the index\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "# divied into two part\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define the sampler\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,batch_size=batch_size,\n",
        "    sampler = train_sampler,num_workers = num_workers)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_data,batch_size=batch_size,\n",
        "    sampler = valid_sampler,num_workers = num_workers)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,batch_size=batch_size,num_workers = num_workers)\n",
        "\n",
        "print(valid_loader.dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 6552\n",
            "    Root Location: flower_data/train\n",
            "    Transforms (if any): Compose(\n",
            "                             Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
            "                             CenterCrop(size=(224, 224))\n",
            "                             ToTensor()\n",
            "                             Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            "                         )\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lU27UyfRVDIr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flowers_class = {\"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\", \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\", \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\", \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\", \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\", \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\", \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\", \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\", \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\", \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\", \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\", \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\", \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\", \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\", \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colt's foot\", \"11\": \"snapdragon\", \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\", \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\", \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\", \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\", \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\", \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DqyU5ooVFPc",
        "colab_type": "code",
        "outputId": "6ee55856-bdbb-402d-b1de-fa317678d644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "# load a pretrained model\n",
        "model = models.densenet121(pretrained = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.torch/models/densenet121-a639ec97.pth\n",
            "100%|██████████| 32342954/32342954 [00:02<00:00, 16027840.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "K_w7ao5qVdxz",
        "colab_type": "code",
        "outputId": "a8958ebb-db92-429d-e1f1-6f0a9dc62ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                ('fc1', nn.Linear(1024, 500)),\n",
        "                ('relu', nn.ReLU()),\n",
        "                ('fc2', nn.Linear(500, 102)),\n",
        "                ('output', nn.LogSoftmax(dim=1))\n",
        "                ]))\n",
        "\n",
        "# replace the classifer\n",
        "model.classifier = classifier\n",
        "# check the classifier\n",
        "print(model.classifier)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=500, out_features=102, bias=True)\n",
            "  (output): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ap5wk-1OVpmx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "# set cretrion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "#move tensor to default device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZqpgUx4Vt0a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "def train(model,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          n_epochs,\n",
        "          device, optimizer,\n",
        "          criterion,\n",
        "          name = \"model.pt\",\n",
        "          path = None):\n",
        "\n",
        "    # compare overfited\n",
        "    train_loss_data, valid_loss_data = [], []\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1,n_epochs))\n",
        "        # monitor training loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        accuracy = 0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()  # prep model for training\n",
        "        for images, lebels in train_loader:\n",
        "            # Move input and label tensors to the default device\n",
        "            images, lebels = images.to(device), lebels.to(device)\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            log_ps = model(images)\n",
        "            # calculate the loss\n",
        "            loss = criterion(log_ps, lebels)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update running training loss\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        print(\"\\tTrain Steps: \")\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()  # prep model for evaluation\n",
        "        for data, target in valid_loader:\n",
        "            # Move input and label tensors to the default device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the loss\n",
        "            loss_p = criterion(output, target)\n",
        "            # update running validation loss\n",
        "            valid_loss += loss_p.item() * data.size(0)\n",
        "            # calculate accuracy\n",
        "            #ps = torch.exp(loss_p)\n",
        "            #top_p, top_class = ps.topk(-1, dim=1)\n",
        "            #equals = top_class == target.view(*top_class.shape)\n",
        "            #accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        print(\"\\tValidation Steps: \")\n",
        "        # print training/validation statistics\n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "        # clculate train loss and running loss\n",
        "        train_loss_data.append(train_loss * 100)\n",
        "        valid_loss_data.append(valid_loss * 100)\n",
        "\n",
        "        print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n",
        "              \"\\t Valid Loss:{:.6f}..\".format(valid_loss))\n",
        "              #\"\\tAcceuracy:{:.2f}%\".format(accuracy))\n",
        "\n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('\\tValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_min,\n",
        "                valid_loss))\n",
        "            torch.save(model.state_dict(), name)\n",
        "            valid_loss_min = valid_loss\n",
        "            # save to google drive\n",
        "            if path is not None:\n",
        "                torch.save(model.state_dict(), path)\n",
        "\n",
        "    # loop complete\n",
        "    plt.plot(train_loss_data, label=\"taining loss\")\n",
        "    plt.plot(valid_loss_data, label=\"validation loss\")\n",
        "    plt.legend(frameon=False)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23DvBZHLWFxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1842
        },
        "outputId": "d73b89cc-b228-4d6d-e645-9ffd68d8d685"
      },
      "cell_type": "code",
      "source": [
        "# train model\n",
        "model = train(model,train_loader,valid_loader, 20, device, optimizer, criterion)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:2.071831.. \t Valid Loss:0.526668..\n",
            "\tValidation loss decreased (inf --> 0.526668).  Saving model ...\n",
            "Epoch: 2/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.837522.. \t Valid Loss:0.423651..\n",
            "\tValidation loss decreased (0.526668 --> 0.423651).  Saving model ...\n",
            "Epoch: 3/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.730483.. \t Valid Loss:0.435811..\n",
            "Epoch: 4/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.616050.. \t Valid Loss:0.289617..\n",
            "\tValidation loss decreased (0.423651 --> 0.289617).  Saving model ...\n",
            "Epoch: 5/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.408739.. \t Valid Loss:0.326252..\n",
            "Epoch: 6/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.236734.. \t Valid Loss:0.241353..\n",
            "\tValidation loss decreased (0.289617 --> 0.241353).  Saving model ...\n",
            "Epoch: 7/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:1.130005.. \t Valid Loss:0.180366..\n",
            "\tValidation loss decreased (0.241353 --> 0.180366).  Saving model ...\n",
            "Epoch: 8/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.974285.. \t Valid Loss:0.139920..\n",
            "\tValidation loss decreased (0.180366 --> 0.139920).  Saving model ...\n",
            "Epoch: 9/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.924608.. \t Valid Loss:0.170045..\n",
            "Epoch: 10/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.827380.. \t Valid Loss:0.140753..\n",
            "Epoch: 11/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.799100.. \t Valid Loss:0.105825..\n",
            "\tValidation loss decreased (0.139920 --> 0.105825).  Saving model ...\n",
            "Epoch: 12/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.717131.. \t Valid Loss:0.109125..\n",
            "Epoch: 13/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.657273.. \t Valid Loss:0.143475..\n",
            "Epoch: 14/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.629449.. \t Valid Loss:0.112255..\n",
            "Epoch: 15/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.593886.. \t Valid Loss:0.115923..\n",
            "Epoch: 16/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.556828.. \t Valid Loss:0.109512..\n",
            "Epoch: 17/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.537211.. \t Valid Loss:0.087398..\n",
            "\tValidation loss decreased (0.105825 --> 0.087398).  Saving model ...\n",
            "Epoch: 18/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.480573.. \t Valid Loss:0.087798..\n",
            "Epoch: 19/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.453731.. \t Valid Loss:0.070372..\n",
            "\tValidation loss decreased (0.087398 --> 0.070372).  Saving model ...\n",
            "Epoch: 20/20\n",
            "\tTrain Steps: \n",
            "\tValidation Steps: \n",
            "\tTrain loss:0.455549.. \t Valid Loss:0.105143..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEAmhBBCZIACMiGEECID/wdLd6iZmIjCQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4049fc1550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "v4MtJpkHwGIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4c9059f-73df-4f12-ec1f-4e13179885bf"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LTabP6RLwPmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0a24940c-98d8-4b6d-e9e1-cde496085592"
      },
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/My Drive"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/gdrive/My': No such file or directory\n",
            "ls: cannot access 'Drive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mog3CewExIwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/Jks/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KApgWHS7WLMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model_cifar.pt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RBJVl7uZWMyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check for overfitting\n",
        "plt.plot(train_loss_data, label = \"taining loss\")\n",
        "plt.plot(valid_loss_data, label = \"validation loss\")\n",
        "plt.legend(frameon = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHoVt_pvWOSk",
        "colab_type": "code",
        "outputId": "5edaea98-4d53-4d9b-a1ef-891ae2cc49b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(102))\n",
        "class_total = list(0. for i in range(102))\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  # iterate over test data\n",
        "  for data, target in test_loader:\n",
        "      # move tensors to GPU if CUDA is available\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model(data)\n",
        "      # calculate the batch loss\n",
        "      loss = criterion(output, target)\n",
        "      # update test loss \n",
        "      test_loss += loss.item()*data.size(0)\n",
        "      # convert output probabilities to predicted class\n",
        "      _, pred = torch.max(output, 1)    \n",
        "      # compare predictions to true label\n",
        "      correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "      # calculate test accuracy for each object class\n",
        "      for i in range(batch_size):\n",
        "          label = target.data[i]\n",
        "          class_correct[label] += correct[i].item()\n",
        "          class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d82b9695da36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m# calculate test accuracy for each object class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m           \u001b[0mclass_correct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mclass_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 18 is out of bounds for dimension 0 with size 18"
          ]
        }
      ]
    }
  ]
}