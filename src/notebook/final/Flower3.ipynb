{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iamsdt/UdacityPyTorch/blob/master/src/notebook/final/Flower3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9nSNIIzc-Zid",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zIMNUZV-eFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7622e801-a332-4ce6-d232-6dd39cff5a2b"
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "\n",
        "!unzip -qq flower_data.zip\n",
        "\n",
        "print(\"Data loaded\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wl7lzI-i-jD4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# view random image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "data_dir = \"flower_data\"\n",
        "TRAIN_DATA_DIR = \"{}/train\".format(data_dir)\n",
        "FILE_DIR = str(np.random.randint(1,103))\n",
        "print(\"Class Directory: \",FILE_DIR)\n",
        "for file_name in os.listdir(os.path.join(TRAIN_DATA_DIR, FILE_DIR))[1:3]:\n",
        "    img_array = cv2.imread(os.path.join(TRAIN_DATA_DIR, FILE_DIR, file_name))\n",
        "    img_array = cv2.resize(img_array,(224, 224), interpolation = cv2.INTER_CUBIC)\n",
        "    plt.imshow(img_array)\n",
        "    plt.show()\n",
        "    print(img_array.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsUtrAta_HUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load train class\n",
        "!wget -c https://raw.githubusercontent.com/Iamsdt/UdacityPyTorch/master/src/notebook/Train.py\n",
        "\n",
        "import Train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXjk7zq4_N9B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create train and test loader\n",
        "data_dir = 'flower_data'\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transform_valid = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# ceate data loader\n",
        "train_loader, valid_loader, test_loader = Train.prepare_loader(data_dir,transform_train,transform_valid,test_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJkJfs8X_UcR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "# load a pretrained model\n",
        "model = models.densenet121(pretrained = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YCzVpoT2_W0a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from torch import nn\n",
        "\n",
        "# create a simple classifier\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                ('fc1', nn.Linear(1024, 500)),\n",
        "                ('relu', nn.ReLU()),\n",
        "                ('fc2', nn.Linear(500, 102)),\n",
        "                ('output', nn.LogSoftmax(dim=1))\n",
        "                ]))\n",
        "\n",
        "# replace the classifer\n",
        "model.classifier = classifier\n",
        "# check the classifier\n",
        "print(model.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQWUXfsJIChT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "# set cretrion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "#move tensor to default device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqTrlECGINy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model, train_loss,valid_loss = Train.train_model(\n",
        "    model,train_loader,valid_loader, 1, device, optimizer,scheduler, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VufSsYypJU4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "import os\n",
        "classes = os.listdir(\"{}/valid\".format(data_dir))\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "img = images.numpy()\n",
        "\n",
        "# move model inputs to cuda, if GPU available\n",
        "images = images.to(device)\n",
        "\n",
        "model.eval() # Required for Evaluation/Test\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "if type(output) == tuple:\n",
        "            output, _ = output\n",
        "# convert output probabilities to predicted class\n",
        "_, preds_tensor = torch.max(output, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) # if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "for idx in np.arange(12):\n",
        "    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n",
        "    ax.set_title(\"Pr: {} Ac: {}\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-XmBkBzIU9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "# Test our Model Performance with Gabriele Picco's Program\n",
        "!wget -c https://raw.githubusercontent.com/GabrielePicco/deep-learning-flower-identifier/master/test_model_pytorch_facebook_challenge.py\n",
        "\n",
        "import test_model_pytorch_facebook_challenge as test\n",
        "\n",
        "testset_path=\"{}/valid\".format(data_dir)\n",
        "v = test.calc_accuracy(model, input_image_size=224, testset_path=testset_path)\n",
        "print(\"Mean accuracy: \",v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PcuZH8bJOFsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test accuracy with google data set\n",
        "v = test.calc_accuracy(model, input_image_size=224,use_google_testset=True)\n",
        "print(\"Mean accuracy: \",v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gprQlZ0Izai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plost solution\n",
        "# helper class\n",
        "def process_image(image_path):\n",
        "    \"\"\"\n",
        "    Scales, crops, and normalizes a PIL image for a PyTorch\n",
        "    model, returns an Numpy array\n",
        "    \"\"\"\n",
        "    # Open the image\n",
        "    from PIL import Image\n",
        "    img = Image.open(image_path)\n",
        "    # Resize\n",
        "    if img.size[0] > img.size[1]:\n",
        "        img.thumbnail((10000, 256))\n",
        "    else:\n",
        "        img.thumbnail((256, 10000))\n",
        "    # Crop\n",
        "    left_margin = (img.width - 224) / 2\n",
        "    bottom_margin = (img.height - 224) / 2\n",
        "    right_margin = left_margin + 224\n",
        "    top_margin = bottom_margin + 224\n",
        "    img = img.crop((left_margin, bottom_margin, right_margin,\n",
        "                    top_margin))\n",
        "    # Normalize\n",
        "    img = np.array(img) / 255\n",
        "    mean = np.array([0.485, 0.456, 0.406])  # provided mean\n",
        "    std = np.array([0.229, 0.224, 0.225])  # provided std\n",
        "    img = (img - mean) / std\n",
        "\n",
        "    # Move color channels to first dimension as expected by PyTorch\n",
        "    img = img.transpose((2, 0, 1))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    # PyTorch tensors assume the color channel is first\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.transpose((1, 2, 0))\n",
        "\n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "\n",
        "    # Image needs to be clipped between 0 and 1\n",
        "    image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "# Class Prediction\n",
        "\n",
        "def predict(image_path, model, top_num=5):\n",
        "    \"\"\"\n",
        "    Predict the class of an image, given a model\n",
        "    :param image_path:\n",
        "    :param model:\n",
        "    :param top_num:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Process image\n",
        "    img = process_image(image_path)\n",
        "\n",
        "    # Numpy -> Tensor\n",
        "    image_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
        "    # Add batch of size 1 to image\n",
        "    model_input = image_tensor.unsqueeze(0)\n",
        "\n",
        "    image_tensor.to('cpu')\n",
        "    model_input.to('cpu')\n",
        "    model.to('cpu')\n",
        "\n",
        "    # Probs\n",
        "    probs = torch.exp(model.forward(model_input))\n",
        "\n",
        "    # Top probs\n",
        "    top_probs, top_labs = probs.topk(top_num)\n",
        "    top_probs = top_probs.detach().numpy().tolist()[0]\n",
        "    top_labs = top_labs.detach().numpy().tolist()[0]\n",
        "\n",
        "    # Convert indices to classes\n",
        "    idx_to_class = {val: key for key, val in\n",
        "                    model.class_to_idx.items()}\n",
        "    top_labels = [idx_to_class[lab] for lab in top_labs]\n",
        "    top_flowers = [cat_to_name[idx_to_class[lab]] for lab in top_labs]\n",
        "    return top_probs, top_labels, top_flowers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jj_38a4DJDBw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Sanity Checking\n",
        "def plot_solution(image_path, model):\n",
        "    \"\"\"\n",
        "    Plot an image with the top 5 class prediction\n",
        "    :param image_path:\n",
        "    :param model:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Set up plot\n",
        "    plt.figure(figsize=(6, 10))\n",
        "    ax = plt.subplot(2, 1, 1)\n",
        "    # Set up title\n",
        "    flower_num = image_path.split('/')[3]\n",
        "    title_ = cat_to_name[flower_num]\n",
        "    # Plot flower\n",
        "    img = process_image(image_path)\n",
        "    imshow(img, ax, title=title_);\n",
        "    # Make prediction\n",
        "    probs, labs, flowers = predict(image_path, model)\n",
        "    # Plot bar chart\n",
        "    plt.subplot(2, 1, 2)\n",
        "    sns.barplot(x=probs, y=flowers, color=sns.color_palette()[0]);\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bP204Cn5JHrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# visualize the solution\n",
        "valid_dir = \"{}/valid\".format(data_dir)\n",
        "image_path = os.path.join(valid_dir, '28/image_05265.jpg')\n",
        "plot_solution(image_path, model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}